This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2024-11-07T15:24:29.670Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
docs/
  example_list.txt
ROTLA/
  __init__.py
  aligned_bases_from_psl.py
  cli.py
  compile_breakpoint_results.py
  ROTLA.py
HISTORY.md
LICENSE
paths.cfg
README.md
setup.py

================================================================
Repository Files
================================================================

================
File: docs/example_list.txt
================
HUMAN_MITO_S1.breakpoints.txt	HM1
HUMAN_MITO_S2.breakpoints.txt	HM2
HUMAN_MITO_S3.breakpoints.txt	HM3
HUMAN_MITO_S4.breakpoints.txt	HM4
HUMAN_MITO_S5.breakpoints.txt	HM5
HUMAN_MITO_S6.breakpoints.txt	HM6
HUMAN_MITO_S7.breakpoints.txt	HM7
HUMAN_MITO_S8.breakpoints.txt	HM8
HUMAN_MITO_S9.breakpoints.txt	HM9
HUMAN_MITO_S10.breakpoints.txt	HM10

================
File: ROTLA/__init__.py
================
# -*- coding: utf-8 -*-

"""Top-level package for ROTLA."""

__author__ = """Christopher Andrew Lavender, Adam Burkholder"""
__email__ = 'c.andrew.lavender@gmail.com, adam.burkholder@nih.gov'
__version__ = '0.1.0'

import os
import ConfigParser

PATHS = dict()
config = ConfigParser.ConfigParser()
config.read(os.path.join(
    os.path.dirname(os.path.abspath(__file__)), '../config', 'paths.cfg'))
for key, value in config.items('paths'):
    PATHS[key] = value

================
File: ROTLA/aligned_bases_from_psl.py
================
import sys
from collections import defaultdict


def count_ref_bases(ref):

    total = 0
    with open(ref) as f:
        for line in f:
            if line[0] != ">":
                total += len(line.strip())

    return total

def read_blocks(input_file, blocks):

    with open(input_file) as f:

        for i in range(5):
            f.next()

        for line in f:
            line_split = line.strip().split()

            read_name = line_split[9]
            block_sizes = line_split[18]
            block_starts = line_split[20]

            for start, size in zip(
                block_starts.split(',')[:-1],
                block_sizes.split(',')[:-1],
            ):
                blocks[read_name].add((
                    int(start) + 1,
                    int(start) + int(size),
                ))

        return blocks


def count_aligned_bases(block_dict, seq_length):

    def check_overlap(region_1, region_2):
        pass

    total = 0

    for blocks in block_dict.values():

        # Account for padded sequence
        _blocks = []
        for block in blocks:
            if block[0] <= seq_length and block[1] <= seq_length:
                _blocks.append(block)
            if block[0] <= seq_length and block[1] > seq_length:
                _blocks.append([block[0], seq_length])
                _blocks.append([1, block[1] - seq_length])
            if block[0] > seq_length and block[1] > seq_length:
                _blocks.append([block[0] - seq_length, block[1] - seq_length])
        blocks = _blocks

        overlap = set()
        for block in blocks:
            overlap = overlap | set(range(block[0], block[1] + 1))

        total += len(overlap)

    return total

def get_aligned_bases(input_prefix, ref):

    ref_length = count_ref_bases(ref)  

    blocks = defaultdict(set)
    blocks = read_blocks(input_prefix + '.read_1.psl', blocks)
    blocks = read_blocks(input_prefix + '.read_2.psl', blocks)

    count = count_aligned_bases(blocks, ref_length)

    with open(input_prefix + '.aligned_bases.txt', 'w') as OUTPUT:
        OUTPUT.write('{}\t{}\n'.format(input_prefix,count))

if __name__ == '__main__':

    if len(sys.argv) < 3:
        sys.stdout.write("Usage: " + sys.argv[0] + "\n           <PSL file prefix>\n           <Reference sequence>\n")
        exit()

    get_aligned_bases(sys.argv[1], sys.argv[2])

================
File: ROTLA/cli.py
================
# -*- coding: utf-8 -*-

"""Console script for ROTLA."""

import click
import os

from ROTLA import ROTLA as _find_breakpoints
from compile_breakpoint_results import compile_breakpoints as _compile_breakpoints
from aligned_bases_from_psl import get_aligned_bases as _get_aligned_bases

@click.group()
def main(args=None):
    pass

@main.command()
@click.option('--length', type=int, help='Minimum required alignment length, default = 25',
              default=25)
@click.argument('read_1_fastq_file', type=str)
@click.argument('read_2_fastq_file', type=str)
@click.argument('reference_sequence', type=str)
@click.argument('output_prefix', type=str)
def find_breakpoints(read_1_fastq_file, read_2_fastq_file, reference_sequence,
                     output_prefix, length):
    '''
    Identify mitochondrial breakpoints.

    Given a set of paired-end FASTQ files and FASTA reference sequence,
    identify breakpoint coordinates and determine count of supporting
    reads.

    This command will produce the following output files, with each
    name below preceded by the provided output_prefix:

    .read_1.psl         Output of Read 1 FASTQ blat alignment in psl format
    .read_2.psl         Output of Read 2 FASTQ blat alignment in psl format
    .read_1.blat.out    Content written to STDOUT during Read 1 blat alignment
    .read_2.blat.out    Content written to STDOUT during Read 2 blat alignment
    .breakpoints.txt    Tab-delimited table of breakpoint start, end, counts
    '''
    args = { 'read_1_file_name':read_1_fastq_file,
             'read_2_file_name':read_2_fastq_file,
             'reference_sequence':reference_sequence,
             'output_prefix':output_prefix,
             'length':length }
    _find_breakpoints(**args)

@main.command()
@click.argument('list_file_name', type=str)
@click.argument('output_file_name', type=str)
def compile_breakpoint_results(list_file_name, output_file_name):

    '''
    Combine results from multiple samples.

    Given a list of breakpoint files created using find_breakpoints,
    create a composite table containing counts for all observed
    breakpoints in all files. The input list file must contain
    two tab-separated columns with no header line. Entries in column 1
    should identify the name of a breakpoint file and entries in
    column 2 should specify the corresponding name to be written to
    the header line in the output file.
    '''

    _compile_breakpoints(list_file_name, output_file_name)

@main.command()
@click.argument('input_file_prefix', type=str)
@click.argument('reference_sequence', type=str)
def get_aligned_bases(input_file_prefix, reference_sequence):

    '''
    Count bases aligned by find_breakpoints.

    Given a pair of PSL files produced using find_breakpoints and the FASTA
    reference sequenced used, this command will determine the total count
    of aligned bases and print this value to an output file named
    [input_prefix].aligned_bases.txt. To allow aligned base counts of many
    samples to be easily combined, this output file utlizes a two-column
    tab-delimited format where the first contains the input file prefix and
    the second contains the count itself.
    '''

    _get_aligned_bases(input_file_prefix, reference_sequence)

if __name__ == "__main__":
    main()

================
File: ROTLA/compile_breakpoint_results.py
================
#!/usr/bin/env python

import sys

def compile_breakpoints(input_files, output_file):

    breakpoint_dict = dict()
    id_list = []
    totals_dict = dict()

    def getBreaks(file_name, file_id):
        with open(file_name) as f:
            next(f)
            for line in f:
                breakpoint_0, breakpoint_1, count = line.strip().split("\t")
                count = int(count)
                if (breakpoint_0, breakpoint_1) in breakpoint_dict:
                    breakpoint_dict[(breakpoint_0, breakpoint_1)][file_id] = count
                else:
                    breakpoint_dict[(breakpoint_0, breakpoint_1)] = {file_id:count}

    with open(input_files) as file_list:
        for line in file_list:
            file_name, file_id = line.strip().split()
            getBreaks(file_name, file_id)
            id_list.append(file_id)

    ## ADD ZEROES
    for breakpoint in breakpoint_dict:
        for file_id in id_list:
            if file_id not in breakpoint_dict[breakpoint]:
                breakpoint_dict[breakpoint][file_id] = 0

    ## GET TOTALS
    for breakpoint in breakpoint_dict:
        total = 0
        for file_id in id_list:
            total += breakpoint_dict[breakpoint][file_id]
        totals_dict[breakpoint] = total

    ## SORT BREAKPOINT LIST BY TOTALS
    sorted_breakpoint = sorted(totals_dict, key=lambda k: totals_dict[k], reverse=True)

    with open(output_file, "w") as OUTPUT:
        OUTPUT.write("\t")
        for file_id in id_list:
            OUTPUT.write("\t" + file_id)
        OUTPUT.write("\n")

        for breakpoint in sorted_breakpoint:
            OUTPUT.write(breakpoint[0] + "\t" + breakpoint[1])
            for file_id in id_list:
                OUTPUT.write("\t" + str(breakpoint_dict[breakpoint][file_id]))
            OUTPUT.write("\n")

if __name__ == '__main__':
    if len(sys.argv) < 3:
        sys.stdout.write("Usage: " + sys.argv[0] + "\n           <List of breakpoint files>\n           <Output file name>\n")
        exit()
    else:
        compile_breakpoints(sys.argv[1], sys.argv[2])

================
File: ROTLA/ROTLA.py
================
#!/usr/bin/env python

import sys
import os
import argparse
import copy
import gzip
import re

from subprocess import call
from collections import defaultdict
from __init__ import PATHS

class ROTLA(object):
    
    def __init__(self, **kwargs):
        
        # Set instance variables
        self.read_1_fn = kwargs['read_1_file_name']
        self.read_2_fn = kwargs['read_2_file_name']
        self.ref_fn = kwargs['reference_sequence']
        self.output_header = kwargs['output_prefix']
        self.blat_path = PATHS['blat']
        self.required_alignment_length = kwargs['length']
        
        # File checks
        for fn in [
            self.read_1_fn,
            self.read_2_fn,
            self.ref_fn,
            self.blat_path
        ]:
            os.path.exists(fn)
        
        self.alignment = dict()
        self.breakpoints = dict()
        self.break_count = defaultdict(int)
        
        self.execute()
        
    @staticmethod
    def readReference(fasta_file):
        reference = ""
        header_count = 0
        
        with open(fasta_file) as f:
            for line in f:
                if line[0] != ">":
                    reference += line.strip()
                else:
                    header_count += 1
                
                if header_count > 1:
                    raise StandardError('FASTA contains two headers.')
        
        return reference.upper()

    @staticmethod
    def flex_open(fq):
        if re.search("\.fastq\.gz$", fq):
            handle = gzip.open(fq)
        elif re.search("\.fastq$", fq):
            handle = open(fq)
        else:
            raise StandardError('Input read files must be in *.fastq or *.fastq.gz format.')

        return handle

    @staticmethod
    def makeFASTA(fastq_file, fasta_file):
        count = 0
        with ROTLA.flex_open(fastq_file) as fastq, open(fasta_file, "w") as fasta:
            for line in fastq:
                if count % 4 == 0:
                    fasta.write("> " + line.strip() + "\n")
                if count % 4 == 1:
                    fasta.write(line)
                count += 1
    
    @staticmethod
    def makePaddedFASTA(fasta_file, output_file):
        reference_sequence = ROTLA.readReference(fasta_file)
        
        with open(output_file, "w") as OUTPUT:
            OUTPUT.write("> Padded reference\n")
            OUTPUT.write(reference_sequence + reference_sequence + "\n")

    def cleanFASTA(self):
        os.remove(self.output_header + ".padded_reference.fasta")
        os.remove(self.output_header + ".read_1.fasta")
        os.remove(self.output_header + ".read_2.fasta")
    
    def readAlignments(self, input_read_1_file, input_read_2_file):
        
        def readFile(input_file, read, add_if_present=False):
            with open(input_file) as f:
                
                # Go through BLAT header
                for i in range(5):
                    next(f)
                    
                # Iterate through lines
                for line in f:
    
                    [
                        matches,
                        misMatches,
                        repMatches,
                        nCount,
                        qNumInsert,
                        qBaseInsert,
                        tNumInsert,
                        tBaseInsert,
                        strand,
                        qName,
                        qSize,
                        qStart,
                        qEnd,
                        tName,
                        tSize,
                        tStart,
                        tEnd,
                        blockCount,
                        blockSizes,
                        qStarts,
                        tStarts,
                    ] = line.strip().split()
                    
                    qStarts = qStarts.split(",")[:-1]
                    tStarts = tStarts.split(",")[:-1]
                    blockSizes = blockSizes.split(",")[:-1]
                    
                    q_list = []
                    t_list = []
                    
                    if (len(blockSizes) > 1) or (add_if_present and qName in self.alignment):
                        
                        if qName not in self.alignment:
                            self.alignment[qName] = {'read_1': [], 'read_2': []}
                        
                        for q, t, size in zip(qStarts, tStarts, blockSizes):
                            if strand == "+":
                                q = [
                                    int(q) + 1,
                                    int(q) + int(size),
                                ]
                            if strand == "-":
                                q = [
                                    int(qSize) - int(q) - int(size) + 1,
                                    int(qSize) - int(q),
                                ]
                            
                            t = [
                                int(t) + 1,
                                int(t) + int(size),
                            ]
        
                            for i, value in enumerate(t):
                                if value > self.ref_seq_length:
                                    t[i] = value - self.ref_seq_length
                            
                            q_list.append(q)
                            t_list.append(t)
                        
                        mapped_regions = []
                        for q, t in zip(q_list, t_list):
                            mapped_regions.append({
                                'q': q,
                                't': t,
                            })
                        
                        read_dict = {
                            'mapped_regions': mapped_regions,
                            'strand': strand,
                            'matches': int(matches),
                            'tGap': int(tNumInsert),
                            'qGap': int(qNumInsert),
                        }
                        
                        if read_dict not in self.alignment[qName][read]:
                            self.alignment[qName][read].append({
                                'mapped_regions': mapped_regions,
                                'strand': strand,
                                'matches': int(matches),
                                'tGap': int(tNumInsert),
                                'qGap': int(qNumInsert),
                            })

        readFile(input_read_1_file, 'read_1')
        readFile(input_read_2_file, 'read_2')
        readFile(input_read_1_file, 'read_1', add_if_present=True)
        readFile(input_read_2_file, 'read_2', add_if_present=True)

    def findBreaks(self):
        for query in self.alignment:
            for read, alignments in self.alignment[query].items():

                for alignment in alignments:
                    
                    strand = alignment['strand']
                
                    if strand == '+':
                        sorted_alignments = sorted(alignment['mapped_regions'], key=lambda k: k['q'][0])
                    if strand == '-':
                        sorted_alignments = sorted(alignment['mapped_regions'], key=lambda k: k['q'][0], reverse = True)
                        
                    for i in range(len(sorted_alignments)-1):
                        
                        size_1 = abs(sorted_alignments[i]['q'][1] - sorted_alignments[i]['q'][0]) + 1
                        size_2 = abs(sorted_alignments[i+1]['q'][1] - sorted_alignments[i+1]['q'][0]) + 1
                        
                        if size_1 >= self.required_alignment_length and \
                                size_2 >= self.required_alignment_length:
                            
                            if query not in self.breakpoints:
                                self.breakpoints[query] = {'read_1': set(), 'read_2': set()}
                            
                            self.breakpoints[query][read].add((sorted_alignments[i]['t'][1], sorted_alignments[i+1]['t'][0]))
                            
    def compareBreaksAcrossReads(self, ref_seq):
        
        def leftAlign(breakpoints):
            output_breakpoints = {'read_1': set(), 'read_2': set()}
            padded_seq = ref_seq + ref_seq
            
            for read, breakpoint_list in breakpoints.items():

                for breakpoint in breakpoint_list:
                    breakpoint = list(breakpoint)
                    
                    if breakpoint[1] < breakpoint[0]:
                        breakpoint[1] += self.ref_seq_length
                    
                    repeat = True
                    while repeat:
                        repeat = False
                        
                        del_seq = padded_seq[breakpoint[0]:breakpoint[1]-1]
                        
                        index = 1
                        while index <= len(del_seq):
                            if del_seq[-index:] == padded_seq[breakpoint[0]-index:breakpoint[0]]:
                                breakpoint[0] -= index
                                breakpoint[1] -= index
                                repeat = True
                                break
                            index += 1
                    
                    if breakpoint[1] > self.ref_seq_length:
                        breakpoint[1] -= self.ref_seq_length

                    output_breakpoints[read].add(tuple(breakpoint))
            
            return output_breakpoints
        
        def findNestedDeletions(breakpoints):
            output_breakpoints = {'read_1': set(), 'read_2': set()}
            
            breaklist = []
            for read, breakpoint_list in breakpoints.items():
                for breakpoint in breakpoint_list:
                    breaklist.append([read, breakpoint[0], breakpoint[1]])

            repeat = True
            while repeat:
                repeat = False
                aligned_breaklist = copy.copy(breaklist)
                
                for i, break_1 in enumerate(breaklist):
                    for j, break_2 in enumerate(breaklist):
                        if break_1 != break_2 and break_1[1] >= break_2[1] and break_1[2] <= break_2[2] and (break_1[1] != break_2[1] or break_1[2] != break_2[2]):
                            aligned_breaklist[j] = [break_2[0], break_1[1], break_1[2]]
                            repeat = True
                
                breaklist = aligned_breaklist
            
            for breakpoint in breaklist:
                output_breakpoints[breakpoint[0]].add((breakpoint[1], breakpoint[2]))
            
            return output_breakpoints
        
        def removeConflictingDeletions(query, breakpoints):
            
            def overlapsOther(breakpoint, query, break_read):
                if break_read == 'read_1':
                    read = 'read_2'
                if break_read == 'read_2':
                    read = 'read_1'
                
                for alignment in self.alignment[query][read]:
                    strand = alignment['strand']
                    mapped_regions = alignment['mapped_regions']
                    
                    if strand == '+':
                        sorted_regions = sorted(mapped_regions, key=lambda k: k['q'][0])
                    if strand == '-':
                        sorted_regions = sorted(mapped_regions, key=lambda k: k['q'][0], reverse = True)
                    
                    t_range = [(sorted_regions[0]['t'][0], sorted_regions[-1]['t'][1])]

                    if t_range[0][0] > t_range[0][1]:
                        t_range = [(1, t_range[0][1]), (t_range[0][0], self.ref_seq_length)]
                    
                    for _range in t_range:
                        if breakpoint[0] >= _range[0] and breakpoint[0] <= _range[1] and \
                            breakpoint[1] >= _range[0] and breakpoint[1] <= _range[1]:
                                return True
                
                return False
            
            output_breakpoints = {'read_1': set(), 'read_2': set()}
            
            breaklist = []
            for read, breakpoint_list in breakpoints.items():
                for breakpoint in breakpoint_list:
                    breaklist.append([read, breakpoint[0], breakpoint[1]])
            cleaned_breaklist = copy.copy(breaklist)
            
            for break_1 in breaklist:
                if overlapsOther((break_1[1], break_1[2]), query, break_1[0]):
                    other_read = False
                    for break_2 in breaklist:
                        if break_1[0] != break_2[0] and break_1[1] == break_2[1] and break_1[2] == break_2[2]:
                            other_read = True
                    if not other_read:
                        cleaned_breaklist.remove(break_1)
            
            for breakpoint in cleaned_breaklist:
                output_breakpoints[breakpoint[0]].add((breakpoint[1], breakpoint[2]))
            
            return output_breakpoints
        
        for query in self.breakpoints:
            breakpoints = copy.copy(self.breakpoints[query])
            
            breakpoints = leftAlign(breakpoints)
            breakpoints = findNestedDeletions(breakpoints)
            breakpoints = removeConflictingDeletions(query, breakpoints)
            
            self.breakpoints[query] = breakpoints
    
    def compileBreaks(self):
        
        for query in self.breakpoints:
            break_set = set()
            
            for breakpoint_list in self.breakpoints[query].values():
                for breakpoint in breakpoint_list:
                    break_set.add(tuple(breakpoint))
        
            for breakpoint in break_set:
                self.break_count[breakpoint] += 1
    
    def compareAcrossAllBreaks(self, ref_seq):
        
        repeat = True
        while repeat:
            repeat = False
            
            for break_1 in self.break_count.keys():
                for break_2 in self.break_count.keys():
                    if break_1 != break_2 and break_1[0] < break_2[0] and break_1[1] > break_2[0] and break_1[1] < break_2[1]:
                        offset_1 = ref_seq[break_1[0]:break_2[0]]
                        offset_2 = ref_seq[break_1[1]-1:break_2[1]-1]
                        if offset_1 == offset_2:
                            self.break_count[break_1] += self.break_count[break_2]
                            self.break_count.pop(break_2, None)

                            repeat = True
    
    def printBreaks(self):
        
        def checkBreakPosition(position):
            if position == 0:
                return self.ref_seq_length
            elif position == self.ref_seq_length + 1:
                return 1
            return position
        
        break_list = []
        for breakpoint, count in self.break_count.items():
            if breakpoint[0]+1 != breakpoint[1]:
                start = checkBreakPosition(breakpoint[0]+1)
                end = checkBreakPosition(breakpoint[1]-1)
                break_list.append([start, end, count])
        
        with open(self.output_header + ".breakpoints.txt", "w") as OUTPUT:
            OUTPUT.write('Start\tEnd\tCount\n')
            for breakpoint in sorted(break_list, key=lambda k: (int(k[0]), int(k[1]), -int(k[2]))):
                OUTPUT.write(str(breakpoint[0]) + '\t' + str(breakpoint[1]) + "\t" + str(breakpoint[2]) + "\n")
    
    def execute(self):
        
        # Make FASTA files from DNA-seq
        self.makeFASTA(self.read_1_fn, self.output_header + ".read_1.fasta")
        self.makeFASTA(self.read_2_fn, self.output_header + ".read_2.fasta")
        
        # Make padded reference
        padded_fn = self.output_header + ".padded_reference.fasta"
        self.makePaddedFASTA(self.ref_fn, padded_fn)
        
        # Read in reference
        ref_seq = self.readReference(self.ref_fn).upper()
        self.ref_seq_length = len(ref_seq)
        
        # Perform alignments
        with open(self.output_header + ".read_1.blat.out", "w") as blat_out:
            call([self.blat_path, padded_fn, self.output_header + ".read_1.fasta", self.output_header + ".read_1.psl"], stdout=blat_out)
        with open(self.output_header + ".read_2.blat.out", "w") as blat_out:
            call([self.blat_path, padded_fn, self.output_header + ".read_2.fasta", self.output_header + ".read_2.psl"], stdout=blat_out)
        
        # Read alignments
        self.readAlignments(self.output_header + ".read_1.psl", self.output_header + ".read_2.psl")

        self.findBreaks()
        self.compareBreaksAcrossReads(ref_seq)
        self.compileBreaks()
        self.compareAcrossAllBreaks(ref_seq)
        self.printBreaks()
        self.cleanFASTA()

if __name__ == '__main__':
    parser = argparse.ArgumentParser()

    parser.add_argument('read_1_file_name', type=str, help='Read 1 file')
    parser.add_argument('read_2_file_name', type=str, help='Read 2 file')
    parser.add_argument('reference_sequence', type=str, help='Reference sequence in FASTA format')
    parser.add_argument('output_prefix', type=str, help='Prefix for output file name')
    parser.add_argument('--length', type=int, help='Minimum required alignment length', default=25)
    args = parser.parse_args()

    ROTLA(**vars(args))

================
File: HISTORY.md
================
## history

### 0.1.0

* Initial release.

================
File: LICENSE
================
MIT License

Copyright (c) 2017, Christopher Andrew Lavender

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

================
File: paths.cfg
================
[paths]
blat = blat

================
File: README.md
================
# ROTLA
ROTLA (Reader of the Lost Arcs) is a Python package that applies a split-read approach to detect deletions in mitochondrial genomes.

## Requirements
ROTLA was developed using Python 2.7.13. In addition to requirements specified in setup.py, ROTLA requires installation of the BLAT command-line alignment utility. BLAT binaries may be downloaded from the UCSC Genome Browser here:
* [UCSC Utilities Download Page](http://hgdownload.soe.ucsc.edu/downloads.html#source_downloads)

## Installation
The location of the BLAT executable must be specified prior to installation. To do this, manually edit the path in `paths.cfg` using a text editor.

After the path has been set, install ROTLA using:
```
python setup.py install
```
Users without administrative privileges may install ROTLA in their home directories by appending '--user' to the command above. The ROTLA package can then be executed as ${HOME}/.local/bin/ROTLA, or simply, ROTLA, provided the user adds the location ${HOME}/.local/bin to their PATH environment variable.

## Usage
Muliple functions are accessible using ROTLA's command line interface. General usage is as follows:
```
ROTLA COMMAND [OPTIONS] [ARGS]...
```
Available commands:
* [compile-breakpoint-results](#compile-breakpoint-results)
* [find-breakpoints](#find-breakpoints)
* [get-aligned-bases](#get-aligned-bases)

### compile-breakpoint-results
```
ROTLA compile-breakpoint-results [OPTIONS] LIST_FILE_NAME OUTPUT_FILE_NAME
```
Given a list of breakpoint files, create a composite table containing counts for all observed breakpoints in all files. The input list file must contain two tab-separated columns with no header line. Entries in column 1 should identify the name of a breakpoint file and entries in column 2 should specify the corresponding name to be written to the header line in the output file. See `example_list.txt` in the `docs` folder for an illustration of this format.

### find-breakpoints
```
ROTLA find-breakpoints [OPTIONS] READ_1_FASTQ_FILE READ_2_FASTQ_FILE REFERENCE_SEQUENCE OUTPUT_PREFIX
```
Given a set of paired-end FASTQ files and FASTA reference sequence, identify breakpoint coordinates and determine count of supporting reads.
This command will produce the following output files, with each name below preceded by the provided `OUTPUT_PREFIX`:

* `OUTPUT_PREFIX`.read_1.psl

Output of Read 1 FASTQ blat alignment in psl format

* `OUTPUT_PREFIX`.read_2.psl

Output of Read 2 FASTQ blat alignment in psl format

* `OUTPUT_PREFIX`.read_1.blat.out

Content written to STDOUT during Read 1 blat alignment

* `OUTPUT_PREFIX`.read_2.blat.out

Content written to STDOUT during Read 2 blat alignment

* `OUTPUT_PREFIX`.breakpoints.txt

Tab-delimited table of breakpoint start coordinates, end coordinates, and counts of supporting reads

#### Options
* `--length INTEGER`

Minimum required alignment length, default = 25

### get-aligned-bases
```
ROTLA get-aligned-bases [OPTIONS] INPUT_FILE_PREFIX REFERENCE_SEQUENCE
```
Given a pair of PSL files produced using find_breakpoints and the FASTA reference sequence, this command will determine the total count of aligned bases and print this value to an output file named `INPUT_PREFIX`.aligned_bases.txt. To allow aligned base counts of many samples to be easily combined, this output file utlizes a two-column tab-delimited format where the first contains the input file prefix and the second contains the count itself.

## Authors
ROTLA was conceptualized by Christopher Lavender and Scott Lujan. ROTLA was written by Christopher Lavender and Adam Burkholder.

## License
This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.

================
File: setup.py
================
#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""The setup script."""

from setuptools import setup, find_packages

with open('README.md') as readme_file:
    readme = readme_file.read()

with open('HISTORY.md') as history_file:
    history = history_file.read()

requirements = [
    'Click>=6.0,<=7.1.2',
]

setup(
    name='ROTLA',
    version='0.1.0',
    description="Split-read mapper for detecting mitochondrial deletions",
    long_description=readme + '\n\n' + history,
    author="Christopher Andrew Lavender, Adam Burkholder",
    author_email='c.andrew.lavender@gmail.com, adam.burkholder@nih.gov',
    url='https://github.com/NIEHS/ROTLA',
    packages=find_packages(include=['ROTLA']),
    entry_points={
        'console_scripts': [
            'ROTLA=ROTLA.cli:main'
        ]
    },
    include_package_data=True,
    install_requires=requirements,
    license="MIT license",
    zip_safe=False,
    keywords='ROTLA',
    classifiers=[
        'Development Status :: 3 - Alpha',
        'Intended Audience :: Developers',
        'License :: OSI Approved :: MIT License',
        'Natural Language :: English',
        "Programming Language :: Python :: 2",
        'Programming Language :: Python :: 2.6',
        'Programming Language :: Python :: 2.7',
    ],
    data_files=[('config', ['paths.cfg'])],
)
